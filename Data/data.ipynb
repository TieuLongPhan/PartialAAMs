{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734dca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import gzip\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import Optional, Union\n",
    "\n",
    "\n",
    "def load_json_from_raw_github(\n",
    "    url: str,\n",
    "    as_frame: bool = True,\n",
    "    lines: Optional[bool] = None,\n",
    ") -> Union[pd.DataFrame, list, dict]:\n",
    "    # Fetch remote content\n",
    "    r = requests.get(url, stream=True)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    buf = io.BytesIO(r.content)\n",
    "\n",
    "    # Try decompressing as gzip; fall back to plain text if not gzipped\n",
    "    try:\n",
    "        with gzip.GzipFile(fileobj=buf) as fh:\n",
    "            text = fh.read().decode(\"utf-8\")\n",
    "    except (OSError, gzip.BadGzipFile):\n",
    "        buf.seek(0)\n",
    "        text = buf.read().decode(\"utf-8\")\n",
    "\n",
    "    # Determine NDJSON (lines) mode if user didn't force it\n",
    "    if lines is None:\n",
    "        # Heuristic: multiple lines and many lines beginning with '{'\n",
    "        stripped = text.lstrip()\n",
    "        is_ndjson = (\"\\n\" in text) and stripped.startswith(\"{\") and (\"\\n{\" in text)\n",
    "        lines_mode = is_ndjson\n",
    "    else:\n",
    "        lines_mode = bool(lines)\n",
    "\n",
    "    # Parse and return\n",
    "    if as_frame:\n",
    "        # Try to produce a DataFrame where possible\n",
    "        try:\n",
    "            if lines_mode:\n",
    "                return pd.read_json(io.StringIO(text), lines=True)\n",
    "            else:\n",
    "                return pd.read_json(io.StringIO(text))\n",
    "        except ValueError:\n",
    "            # pd.read_json couldn't parse (maybe nested, or not table-like) -> fallback\n",
    "            return json.loads(text)\n",
    "    else:\n",
    "        if lines_mode:\n",
    "            return [json.loads(line) for line in text.splitlines() if line.strip()]\n",
    "        else:\n",
    "            return json.loads(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f43aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/TieuLongPhan/SynKit/raw/refs/heads/att_graph/Data/Benchmark/data_aam.json.gz\"\n",
    "df = load_json_from_raw_github(url, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0243bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from synkit.Chem.Reaction.canon_rsmi import CanonRSMI\n",
    "from synkit.IO.debug import configure_warnings_and_logs\n",
    "\n",
    "configure_warnings_and_logs(False, True)\n",
    "\n",
    "maps = ['rxn_mapper', 'graphormer', 'local_mapper']\n",
    "\n",
    "def _canon_task(value, mapper):\n",
    "    smi = value.get(mapper)\n",
    "    if not smi:\n",
    "        return None\n",
    "    try:\n",
    "        \n",
    "        return CanonRSMI().canonicalise(smi).canonical_rsmi\n",
    "    except Exception as exc:\n",
    "        return None\n",
    "\n",
    "tasks = [(row, m) for row in df for m in maps]\n",
    "\n",
    "results = Parallel(n_jobs=4, verbose=2, backend=\"loky\")(\n",
    "    delayed(_canon_task)(row, m) for row, m in tasks\n",
    ")\n",
    "\n",
    "# keep only successful canonical rsmi strings\n",
    "final = [r for r in results if r is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce9435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = list(set(final))\n",
    "print(len(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d1346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synkit.Chem.Reaction.standardize import Standardize\n",
    "from synkit.Chem.Reaction.balance_check import BalanceReactionCheck\n",
    "std = Standardize()\n",
    "check = BalanceReactionCheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb035ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _process(idx, value):\n",
    "    try:\n",
    "        rxn = std.fit(value, True)\n",
    "        balance = check.rsmi_balance_check(rxn)\n",
    "        new = {\n",
    "            'R-id': f'R-{idx}',\n",
    "            'rxn': rxn,\n",
    "            'aam': value,\n",
    "            'balance': balance\n",
    "        }\n",
    "        return idx, new\n",
    "    except Exception as exc:\n",
    "        \n",
    "        return idx, None\n",
    "\n",
    "tasks = list(enumerate(final))  \n",
    "try:\n",
    "    results = Parallel(n_jobs=4, backend='loky', verbose=2)(\n",
    "        delayed(_process)(idx, val) for idx, val in tasks\n",
    "    )\n",
    "except Exception:\n",
    "    # fallback if objects aren't picklable\n",
    "    backend = \"threading\"\n",
    "    results = Parallel(n_jobs=4, backend='loky', verbose=2)(\n",
    "        delayed(_process)(idx, val) for idx, val in tasks\n",
    "    )\n",
    "\n",
    "results.sort(key=lambda t: t[0])\n",
    "data = [item for (_, item) in results if item is not None]\n",
    "data = [value for value in data if value['balance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dea6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from synkit.IO import rsmi_to_its\n",
    "\n",
    "def _compute_its(idx, item):\n",
    "    try:\n",
    "        its = rsmi_to_its(item['aam'], core=False)\n",
    "        rc  = rsmi_to_its(item['aam'], core=True)\n",
    "        return idx, its, rc\n",
    "    except Exception:\n",
    "        return idx, None, None\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=4, backend=\"loky\", verbose=2)(\n",
    "    delayed(_compute_its)(i, itm) for i, itm in enumerate(data)\n",
    ")\n",
    "\n",
    "\n",
    "for idx, its, rc in results:\n",
    "    data[idx]['ITS'] = its\n",
    "    data[idx]['RC']  = rc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe623f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synkit.Graph.Hyrogen.hcomplete import HComplete\n",
    "\n",
    "comp = HComplete()\n",
    "complete = comp.process_graph_data_parallel(data,its_key='ITS', rc_key = 'RC', n_jobs=4, verbose=2)\n",
    "amb_hydrogen = [value for value in complete if value['ITS'] is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "amb_hydrogen = [{'R-id': value['R-id'], \n",
    "                 'rxn': value['rxn'],\n",
    "                 'aam': value['aam']} for value in amb_hydrogen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b58f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=4, backend=\"loky\", verbose=2)(\n",
    "    delayed(_compute_its)(i, itm) for i, itm in enumerate(amb_hydrogen)\n",
    ")\n",
    "\n",
    "\n",
    "for idx, its, rc in results:\n",
    "    amb_hydrogen[idx]['ITS'] = its\n",
    "    amb_hydrogen[idx]['RC']  = rc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synkit.Graph.Matcher.graph_cluster import GraphCluster\n",
    "from synkit.Utils.utils import stratified_random_sample\n",
    "cls = GraphCluster()\n",
    "result = cls.fit(amb_hydrogen, 'RC', None)\n",
    "data = stratified_random_sample(result, 'class', 1, 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c345a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Iterable, Tuple, List, Pattern\n",
    "\n",
    "def _compile_bracketed_elements_pattern(elements: Tuple[str, ...]) -> Pattern:\n",
    "    elems_sorted = sorted(elements, key=lambda s: -len(s))\n",
    "    alt = \"|\".join(re.escape(e) for e in elems_sorted)\n",
    "    pattern = rf'\\[(?:\\d+)?(?:{alt})(?![A-Za-z])(?:[:@+\\-\\d]*)?\\]'\n",
    "    return re.compile(pattern)\n",
    "\n",
    "def is_single_bracketed_elements_collapse_dots(smiles: str, elements: Iterable[str] = ('H','O')) -> bool:\n",
    "    if not smiles:\n",
    "        return False\n",
    "    elems = tuple(elements)\n",
    "    token_re = _compile_bracketed_elements_pattern(elems)\n",
    "\n",
    "    # find tokens with spans\n",
    "    tokens: List[Tuple[int,int,str]] = [(m.start(), m.end(), m.group()) for m in token_re.finditer(smiles)]\n",
    "    if not tokens:\n",
    "        return False\n",
    "\n",
    "    effective_count = 0\n",
    "    prev_token = None\n",
    "    prev_end = -1\n",
    "\n",
    "    for start, end, text in tokens:\n",
    "        if prev_token is not None and text == prev_token:\n",
    "            # check that the chars between prev_end and start are only dots or whitespace\n",
    "            between = smiles[prev_end:start]\n",
    "            if re.fullmatch(r'[\\s\\.]*', between):\n",
    "                # same run -> skip counting this token\n",
    "                prev_end = end\n",
    "                continue\n",
    "\n",
    "        # new effective token\n",
    "        effective_count += 1\n",
    "        prev_token = text\n",
    "        prev_end = end\n",
    "\n",
    "    return effective_count == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2110ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bug = []\n",
    "for key, value in enumerate(data):\n",
    "    if is_single_bracketed_elements_collapse_dots(value['rxn']):\n",
    "        bug.append(key)\n",
    "\n",
    "data = [value for key, value in enumerate(data) if key not in bug]\n",
    "easier = [value for key, value in enumerate(data) if key != 72]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adc367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synkit.IO import save_to_pickle\n",
    "\n",
    "\n",
    "save_to_pickle(data, './hydrogen.pkl.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c4284",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81cbc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synkit.IO import load_from_pickle\n",
    "from synkit.Graph.Hyrogen.hextend import HExtend\n",
    "data = load_from_pickle('./hydrogen.pkl.gz')\n",
    "\n",
    "# result = HExtend().fit(data[50:60], 'ITS', 'RC', n_jobs=4, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f0f30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e72f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22489ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70859e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "easier = [value for key, value in enumerate(data) if key not in bug]\n",
    "easier = [value for key, value in enumerate(easier) if key != 72]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d9c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = HExtend().fit(easier[0:], 'ITS', 'RC', n_jobs=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d11a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
